В этом репозитории представлены два варианта Dockerfile для сборки образа Apache Airflow: "плохой" (`Dockerfile.bad`) и "хороший" (`Dockerfile.good`). Цель работы — продемонстрировать, как оптимизировать образы, повысить их безопасность и избежать распространенных ошибок при написании Dockerfile.

## Структура репозитория

*   **Dockerfile.bad**: Рабочий, но неоптимизированный файл с нарушением лучших практик.
*   **Dockerfile.good**: Исправленная версия с учетом безопасности и оптимизации слоев.
*   **requirements.txt**: Список Python-зависимостей.
*   **dags/**: Директория с DAG-файлами (используется для монтирования volume).

---

## 1. Сравнение Dockerfile: Анализ ошибок и исправлений

Ниже приведено подробное описание "плохих практик" (Bad Practices), допущенных в `Dockerfile.bad`, и то, как они были исправлены в `Dockerfile.good`.

### Ошибка 1: Использование тега `latest`
**В плохом файле:** `FROM apache/airflow:latest`
**Почему это плохо:** Тег `latest` не детерминирован. Сегодня это версия 2.7, завтра — 3.0. При обновлении базового образа ваше приложение может внезапно перестать работать из-за несовместимости версий API или зависимостей. Вы не контролируете среду.
**Исправление:** В хорошем файле версия зафиксирована жестко:
```dockerfile
FROM apache/airflow:2.7.1-python3.10
```
Это гарантирует, что сборка будет воспроизводимой в любое время.

### Ошибка 2: Работа от пользователя `root` в рантайме
**В плохом файле:** `USER root` устанавливается и остается активным до конца.
**Почему это плохо:** Запуск приложений от root внутри контейнера создает серьезную угрозу безопасности. Если злоумышленник найдет уязвимость в Airflow и выберется из контейнера (container breakout), он получит root-права на хост-машине.
**Исправление:** Мы переключаемся на `root` **только** для установки системных библиотек, а затем возвращаемся к пользователю `airflow`:
```dockerfile
USER airflow
```

### Ошибка 3: Неправильная работа со слоями и кэшем (Layer Caching)
**В плохом файле:**
```dockerfile
COPY dags/ /opt/airflow/dags/
RUN pip install -r requirements.txt
```
**Почему это плохо:** Код приложения (DAGs) меняется часто, а зависимости (`requirements.txt`) — редко. Docker сбрасывает кэш сборки, как только встречает изменившийся слой. Если вы сначала копируете код, то при любом изменении в DAG-файле Docker будет заново переустанавливать все библиотеки `pip install`. Это делает сборку очень долгой.
**Исправление:** Сначала копируем файлы зависимостей и устанавливаем их, и только потом (если нужно) копируем код.
```dockerfile
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
# DAG-файлы в хорошем варианте мы не копируем, а монтируем через Volume (см. ниже)
```

### Ошибка 4: Мусор в слоях и неоптимизированный `apt-get`
**В плохом файле:**
```dockerfile
RUN apt-get update
RUN apt-get install -y vim git nano
```
**Почему это плохо:**
1.  Разделение `update` и `install` может привести к установке устаревших пакетов, если слой с `update` закэширован, а репозитории обновились.
2.  Установка лишних утилит (`vim`, `nano`, `git`) увеличивает размер образа, но не нужна для работы приложения (debugging tools не должны быть в проде).
3.  Кэш apt (`/var/lib/apt/lists`) остается в образе, занимая место.
**Исправление:** Объединение команд, очистка кэша и удаление временных файлов в одном слое (`RUN`):
```dockerfile
RUN apt-get update \
  && apt-get install -y --no-install-recommends build-essential \
  && apt-get autoremove -yqq --purge \
  && apt-get clean \
  && rm -rf /var/lib/apt/lists/*
```

---

## 2. Запуск и использование (Монтирование Volume)

Для запуска "Хорошего" варианта мы используем монтирование volume для доставки кода (DAGs) внутрь контейнера. Это позволяет разрабатывать код локально, не пересобирая образ.

### Сборка образа
```bash
docker build -t my-airflow-good -f Dockerfile.good .
```

### Запуск контейнера (с Volume)
```bash
docker run -d -p 8080:8080 \
  -v $(pwd)/dags:/opt/airflow/dags \
  --name airflow-good \
  my-airflow-good
```
*Теперь Airflow доступен по адресу `localhost:8080`. Логин/пароль по умолчанию можно найти в логах контейнера или файле `standalone_admin_password.txt` внутри контейнера (так как используется режим standalone).*

---

## 3. Плохие практики использования контейнеров (Runtime)

Помимо написания Dockerfile, существуют ошибки при эксплуатации уже готовых контейнеров:

1.  **Хранение важных данных (State) внутри контейнера без Volume.**
    *   *Почему плохо:* Контейнеры эфемерны. Если контейнер упадет, будет удален или пересоздан (что является нормой), все данные базы данных или логи, записанные внутри файловой системы контейнера, исчезнут навсегда.
    *   *Как надо:* Всегда использовать внешние тома (Volumes) или bind mounts для БД и важных файлов.

2.  **Передача секретов (паролей, API-ключей) через переменные окружения в открытом виде (`ENV`).**
    *   *Почему плохо:* Переменные окружения видны любому, кто имеет доступ к `docker inspect` или логам процессов.
    *   *Как надо:* Использовать механизмы Docker Secrets, Kubernetes Secrets или внешние хранилища секретов (Vault), монтируя их как файлы.

---

## 4. Когда НЕ стоит использовать контейнеры

Хотя контейнеризация популярна, она не является "серебряной пулей". Два случая, когда от неё лучше отказаться:

1.  **Приложения с жесткими требованиями к I/O или специфическому "железу".**
    *   Если приложение требует прямого доступа к физическому оборудованию (специфические драйверы видеокарт, кастомные платы ввода-вывода) или критически важна максимальная производительность дисковой подсистемы без оверхеда файловой системы Docker (OverlayFS), лучше использовать "голое железо".

2.  **Монолитные Legacy-приложения с GUI или сложной архитектурой.**
    *   Старые десктопные приложения или огромные монолиты, которые жестко завязаны на конкретную версию ядра ОС, IP-адресацию или требуют сложной ручной настройки GUI-окружения, очень дорого и сложно "запихивать" в контейнер. Затраты на миграцию превысят пользу.